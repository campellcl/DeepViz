import matplotlib.pyplot as plt
# Typing imports:
from PyTorch.Lib.EnumeratedTypes.DatasetNames import DatasetNames
from PyTorch.Lib.EnumeratedTypes.DatasetTypes import DatasetTypes
from torch.utils.data import DataLoader
from torch import Tensor
import torch
import torchvision
import matplotlib.pyplot as plt
import numpy as np


def show_image_batch(dataset_name: DatasetNames, data_loader: DataLoader, unormalized_image_channel_means: Tensor,
                     unormalized_image_channel_standard_deviations: Tensor, human_readable_class_labels: tuple):
    """
    show_image_batch: Displays a de-normalized batch of images from either the training, validation, or testing dataset
     depending on the data_loader instance provided. Additionally, the number of training images displayed in the batch
     is dependent on the settings of the provided data_loader instance.
    :param dataset_name: <EnumeratedTypes.DatasetNames> The name of the the dataset associated with the provided
     DataLoader.
    :param data_loader: <torch.utils.data.DataLoader> An already instantiated DataLoader instance which provides access
     to the training data images to visualize. Because PyTorch DataLoaders are instantiated with a set of image
     transformations, care must be taken to reverse those operations here so we can see the training image in its
     original state.
    :param unormalized_image_channel_means: <torch.Tensor> A tensor containing the mean of each RGB image channel in the
     entire training dataset. This is expected to be in the form: [R, G, B] for color images.
    :param unormalized_image_channel_standard_deviations: <torch.Tensor> A tensor containing the standard deviation
     (std) of each RGB image channel in the entire training dataset. This is expected to be in the form: [R, G, B] for
     color images.
    :param human_readable_class_labels: <tuple> A tuple (by definition immutable) which contains the key-value mapping
     between the encoded class labels (e.g. [0, 1, 2, 3, ...]) and the human readable label name (e.g. 'cat', 'dog',
    'boat', etc.).
    :return None: This method will display a grid of images generated by the provided data_loader instance, alongside
     their correct human-readable class labels. The images will be de-normalized to their original state before being
     plotted.
    """

    # Get random images from the provided dataloader (of the specified batch size):
    image_batch_iterable = iter(data_loader)
    image_batch, labels = image_batch_iterable.next()

    # De-normalize every image in the image_batch:
    for i, img in enumerate(image_batch):
        for img_channel, img_channel_mean, img_channel_std in zip(img, unormalized_image_channel_means,
                                                                  unormalized_image_channel_standard_deviations):
            '''
            The Normalization step: 
                normalized_image_channel = (original_image_channel - original_image_channel_mean) / original_image_channel_standard_deviation
             In Code: 
                norm_img = image_tensor.sub_(img_channel_means).div_(image_channel_standard_deviations)
            Can be reverted with:
                original_image_channel = (normalized_image_channel * original_image_channel_standard_deviation) + original_image_channel_mean
            '''
            img_channel.mul_(img_channel_std).add_(img_channel_mean)

    def imshow(img_tensor):
        """
        imshow: Displays a PyTorch tensor as a human-viewable RGB image; by converting from RGB to numpy's GBR image
         format.
        :param img_tensor: <torch.Tensor> A PyTorch tensor object containing an image of the form: RGB
        :return None: When this method is invoked it will display (via matplotlib) the input PyTorch tensor, as a
         human viewable color image.
        """
        np_img = img_tensor.numpy()
        # Here we transpose because numpy is GBR instead of RGB
        plt.imshow(np.transpose(np_img, (1, 2, 0)))
        plt.show()

    str_labels = [human_readable_class_labels[i] for i in labels]
    imshow(torchvision.utils.make_grid(tensor=image_batch, nrow=len(image_batch), normalize=False))
    print('Ground truth class labels: %s' % [human_readable_class_labels[i] for i in labels])
    # print(' '.join('%5s' % [human_readable_class_labels[i] for i in labels]))

    # num_images = len(image_batch)
    # num_columns = 2
    # titles = str_labels
    # fig = plt.figure()
    # for i, (image, title) in enumerate(zip(image_batch, titles)):
    #     ax = fig.add_subplot(num_columns, np.ceil(num_images / num_columns), i + 1)
    #     imshow(image)
    #     ax.set_title(title)
    #     # np_img = image.numpy()
    #     # np_img = np_img.transpose((1, 2, 0))
    #     # plt.imshow(np_img)
    # fig.set_size_inches(np.array(fig.get_size_inches()) * num_images)
    # plt.show()
    # plt.imsave('test.png')


# class NormalizeInverse(torchvision.transforms.Normalize):
#     """
#     Undoes the normalization and returns the reconstructed images in the input domain.
#     Source: https://discuss.pytorch.org/t/simple-way-to-inverse-transform-normalization/4821/8?u=campellcl
#     Author: Danylo Ulianych
#     """
#
#     def __init__(self, mean, std):
#         mean = torch.as_tensor(data=mean)
#         std = torch.as_tensor(data=std)
#         std_inv = 1 / (std + 1e-7)
#         mean_inv = -mean * std_inv
#         super().__init__(mean=mean_inv, std=std_inv)
#
#     def __call__(self, tensor: Tensor):
#         return super().__call__(tensor=tensor.clone())


# def denormalize_image_tensor(image_tensor: Tensor, image_channel_means: Tensor, image_channel_standard_deviations: Tensor):
#     """
#
#     :param tensor:
#     :param image_channel_means:
#     :param image_channel_standard_deviations:
#     :return:
#     """
#     original_image_tensor: Tensor
#     '''
#     The Normalization step:
#         normalized_image_channel = (original_image_channel - original_image_channel_mean) / original_image_channel_standard_deviation
#      In Code:
#         norm_img = image_tensor.sub_(img_channel_means).div_(image_channel_standard_deviations)
#     Can be reverted with:
#         original_image_channel = (normalized_image_channel * original_image_channel_standard_deviation) + original_image_channel_mean
#     '''
#     original_image_tensor = image_tensor.mul_(image_channel_standard_deviations).add_(image_channel_means)
#     return original_image_tensor